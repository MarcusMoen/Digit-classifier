{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the necessary models and files for making predictions\n",
    "\n",
    "Here we need to download the validation and test datasets we made when making our models. We also need to download all the models and the data and film files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_csv('cleandata/X_val.csv')\n",
    "y_val =pd.read_csv('cleandata/y_val.csv') \n",
    "\n",
    "X_test = pd.read_csv('cleandata/X_test.csv')\n",
    "y_test = pd.read_csv('cleandata/y_test.csv')\n",
    "\n",
    "model_baseline = pickle.load(open('model_baseline.pkl', 'rb'))\n",
    "model_cb = pickle.load(open('model_cb.pkl', 'rb'))\n",
    "correlation_matrix = pickle.load(open('correlation_matrix.pkl', 'rb'))\n",
    "\n",
    "data = pd.read_csv('cleandata/data.csv') \n",
    "film2 = pd.read_csv('cleandata/film2.csv')\n",
    "film = pd.read_csv('cleandata/film.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the baseline model\n",
    "\n",
    "The baseline model makes predictions by first checking if the movie we want to predict is in our model, if it is then it takes out the value at that index and that is the prediction. If the movie is not in our model then it takes the mean of all the values in the model and makes that the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_predict(userid, filmid):\n",
    "    if any(model_baseline.index == filmid):\n",
    "        return model_baseline.loc[filmid][0]\n",
    "    else:\n",
    "        return model_baseline.mean()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating rmse on validation data for our baseline model\n",
    "\n",
    "Here I will calculate the root mean squared error on our validation set. This value will come in handy when I compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for baseline on validation data is 0.9920240555792099\n"
     ]
    }
   ],
   "source": [
    "predicted_baseline = []\n",
    "for i in range(len(X_val)):\n",
    "    predicted_baseline.append(baseline_predict(X_val.iloc[i,0], X_val.iloc[i,1]))\n",
    "\n",
    "mse_baseline = mean_squared_error(y_val, predicted_baseline)\n",
    "print(\"Root Mean Squared Error for baseline on validation data is\", str(np.sqrt(mse_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the content based model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_cb(userid, filmid):\n",
    "    model_user = model_cb[userid] # Extract the model from the dictionary\n",
    "    X = film2.loc[film2['FilmID'] == filmid].drop(['FilmID'], axis=1) # Extract the x values for the movie\n",
    "    X = np.array(X).reshape(1,-1)\n",
    "\n",
    "    pred = model_user.predict(X) # Predict rating\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating rmse on validation data for our content based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for content based on validation data is 1.3294757642943764\n"
     ]
    }
   ],
   "source": [
    "predicted_cb = []\n",
    "# Makes predictions for every user and movie in the validation set\n",
    "for i in range(len(X_val)):\n",
    "    predicted_cb.append(prediction_cb(X_val.iloc[i,0], X_val.iloc[i,1])) \n",
    "\n",
    "mse_cb = mean_squared_error(y_val, predicted_cb)\n",
    "print(\"Root Mean Squared Error for content based on validation data is\", str(np.sqrt(mse_cb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the collaborative model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(data, values='Rangering', columns='FilmID', index='BrukerID') # Make a table of each known rating\n",
    "bruker_mean = table.mean(axis=1)\n",
    "\n",
    "table = table.fillna(0.1)\n",
    "\n",
    "def prediction_collaborative(userid, filmid):\n",
    "    correlation_vector = correlation_matrix.loc[userid, :] # Extract the row in the correlation matrix which represents the user\n",
    "    film_vector = table.loc[:,filmid] # Extract the column in table corresponding to the filmid\n",
    "    has_rated = film_vector.index[film_vector != 0.1].tolist() # Find every user that has rated the given filmid\n",
    "    has_rated_corr = correlation_vector[has_rated] # Find a vector with the correlations with evry person that has rated the filmid\n",
    "\n",
    "    k = 3\n",
    "    k_largest = has_rated_corr.nlargest(k) # Find the k highest correlations\n",
    "    pred = 0\n",
    "    # Calculate the predictions\n",
    "    for i in range(len(k_largest)):\n",
    "        pred += (table.loc[k_largest.index[i], filmid]-bruker_mean[k_largest.index[i]])\n",
    "    pred = bruker_mean.loc[userid] + (1/k)*pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating rmse on validation data for our collaborative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for collaborative on validation data is 0.7007817124570134\n"
     ]
    }
   ],
   "source": [
    "predicted_coll = []\n",
    "# Makes predictions for every user and movie in the validation set\n",
    "for i in range(len(X_val)):\n",
    "    predicted_coll.append(prediction_collaborative(X_val.iloc[i,0], X_val.iloc[i,1]))\n",
    "\n",
    "mse_coll = mean_squared_error(y_val, predicted_coll)\n",
    "print(\"Root Mean Squared Error for collaborative on validation data is\", str(np.sqrt(mse_coll)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with a combined approche\n",
    "\n",
    "For the combined approche I have decided to weigth the two models differently. I have decided to weigth the collaborative model with 3/4 and the content based 1/4. The reason for this is that the collaborative model performed a lot better then the content based and it will make sanse to weigth this prediction more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_combined(userid, filmid):\n",
    "    cont = prediction_cb(userid, filmid) # Makes predictions with the content based model\n",
    "    coll = prediction_collaborative(userid, filmid) # Makes predictions with the collaborative model\n",
    "    pred = (0.25*cont)+(0.75*coll) # Makes a weghted prediction\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating rmse on validation data for our combined approche\n",
    "\n",
    "Instead of using the function above I will use the predictions made on validation data from above. I will do this to save some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for combiend on validation data is 0.7403101343454669\n"
     ]
    }
   ],
   "source": [
    "predicted_cb_w = [i * 0.2 for i in predicted_cb] \n",
    "predicted_coll_w = [i * 0.8 for i in predicted_coll]\n",
    "predicted_comb = []\n",
    "# Makes predictions for every user and movie in the validation set\n",
    "for i in range(len(predicted_coll_w)):\n",
    "    predicted_comb.append(predicted_cb_w[i] + predicted_coll_w[i])\n",
    "\n",
    "mse_comb = mean_squared_error(y_val, predicted_comb)\n",
    "print(\"Root Mean Squared Error for combiend on validation data is\", str(np.sqrt(mse_comb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the four different models based on validation data\n",
    "\n",
    "As one can see for the rmse values for the four different models the collaborative model gained a lower rmse then the three others. And because of this result I would have choosen to use the collaborative model when making predictions. I the cell below I will test the model against the unbiased test set and estimate a perfermance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for collaborative on validation data is 0.7020214854185584\n"
     ]
    }
   ],
   "source": [
    "predicted_coll_test = []\n",
    "for i in range(len(X_test)):\n",
    "    predicted_coll_test.append(prediction_collaborative(X_test.iloc[i,0], X_test.iloc[i,1]))\n",
    "\n",
    "mse_coll_test = mean_squared_error(y_test, predicted_coll_test)\n",
    "print(\"Root Mean Squared Error for collaborative on validation data is\", str(np.sqrt(mse_coll_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see from the result I estimate that my model will have and average error of 0.7 for new unsees data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions for the entire dataset (For all users and all movies)\n",
    "\n",
    "Here we are supposed to make predictions for all users and all movies. Becuase of the time this take I have decided to only make predictions for the first 250 movies. One can easily change the code below such that one can make predictions for the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrukerID      0         1         2         3         4         5     \\\n",
      "FilmID                                                                 \n",
      "0         1.156174  1.770670  2.448580  3.811687  2.391108  2.978528   \n",
      "1         4.139513  3.899817  3.728852  4.203422  3.475259  3.361512   \n",
      "2         3.160736  3.605722  3.714048  4.118542  4.010434  3.209451   \n",
      "3         3.279912  3.027184  3.871290  4.899560  3.587432  2.485781   \n",
      "5         3.469079  3.302847  4.485642  4.289191  3.830698  2.465458   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "267       1.674177  2.553589  3.130304  2.467914  2.934510  1.677569   \n",
      "268       2.132015  1.895780  2.070686  3.025850  1.563227  1.216402   \n",
      "269       3.120774  3.622281  2.490634  3.902742  3.565559  3.527635   \n",
      "270       2.942445  2.000000  3.699050  4.490130  3.302005  3.175524   \n",
      "271       2.470195  3.620914  3.153671  2.525830  3.606265  3.617511   \n",
      "\n",
      "BrukerID      6         7         8         9     ...      6031      6032  \\\n",
      "FilmID                                            ...                       \n",
      "0         2.653161  2.371512  3.414529  2.196119  ...  2.077937  2.784697   \n",
      "1         3.607423  4.897059  5.051193  4.368678  ...  4.518070  5.099144   \n",
      "2         3.415839  4.118542  4.439710  3.439710  ...  3.668542  4.224737   \n",
      "3         3.697033  3.331376  3.742468  5.000000  ...  3.163447  3.587230   \n",
      "5         3.806504  4.042512  4.435258  4.000000  ...  3.589517  5.117523   \n",
      "...            ...       ...       ...       ...  ...       ...       ...   \n",
      "267       2.204257  2.958417  4.065483  1.872122  ...  2.610526  3.449730   \n",
      "268       1.759309  1.843311  2.569627  2.156429  ...  2.689503  2.503611   \n",
      "269       2.325892  4.204063  3.625744  2.808613  ...  3.393137  4.323531   \n",
      "270       2.645637  5.600560  4.623416  2.000000  ...  4.354409  4.142941   \n",
      "271       3.144169  4.390900  3.462529  3.360653  ...  3.740283  3.064447   \n",
      "\n",
      "BrukerID      6033      6034      6035      6036      6037      6038  \\\n",
      "FilmID                                                                 \n",
      "0         2.542330  3.384749  1.797921  1.886061  3.809442  2.197553   \n",
      "1         5.043070  5.303232  3.806049  3.588305  4.595744  2.730942   \n",
      "2         3.978542  3.651875  3.655732  3.681042  4.329068  2.590764   \n",
      "3         3.741731  2.566913  4.246419  3.064282  3.335319  3.157779   \n",
      "5         4.145125  3.223013  2.547577  4.000000  4.006134  2.564678   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "267       2.799226  2.292974  1.755826  2.262069  3.748776  1.573873   \n",
      "268       2.548893  3.011045  1.723033  1.893086  2.965901  0.185008   \n",
      "269       4.502578  3.522436  4.558599  3.534605  3.873430  2.241117   \n",
      "270       3.993576  4.667922  3.703921  4.328825  4.743755  2.973188   \n",
      "271       3.537362  3.154323  2.389483  3.390365  3.000000  3.540730   \n",
      "\n",
      "BrukerID      6039      6040  \n",
      "FilmID                        \n",
      "0         4.436774  2.416052  \n",
      "1         4.912984  4.518884  \n",
      "2         4.634671  4.044772  \n",
      "3         3.509963  3.550162  \n",
      "5         3.273165  4.153028  \n",
      "...            ...       ...  \n",
      "267       3.943945  2.744220  \n",
      "268       3.064683  3.091381  \n",
      "269       4.076769  4.516681  \n",
      "270       4.312622  3.596604  \n",
      "271       3.395772  3.700318  \n",
      "\n",
      "[250 rows x 6040 columns]\n"
     ]
    }
   ],
   "source": [
    "# Makes a DataFrame with all the known ratings\n",
    "predictions = pd.pivot_table(data, values='Rangering', columns='BrukerID', index='FilmID')\n",
    "columns = list(predictions.columns)\n",
    "rows = list(predictions.index)\n",
    "predictions = predictions.fillna(0.1).iloc[0:250, :] # Remove the .iloc to make predictions for the entire dataset\n",
    "\n",
    "# Predicting the unknown values with the predicted values\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions.iloc[0])):\n",
    "        if predictions.iloc[i,j] == 0.1:\n",
    "            predictions.iloc[i,j] = prediction_collaborative(columns[j], rows[i])\n",
    "            \n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('cleandata/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the project\n",
    "\n",
    "Ratings are given in integer between 1 and 5. When I make predictions I have decided not to take this into account. The reason for this is that when I make the website I give a list of 10 movies, we will get a more accurate result by using float not integer numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How I want my website to make predictions\n",
    "\n",
    "Since I have some trouble running the website on on the local host I have decided to make a demonstration of how the code in the app2.py should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Make Them Die Slowly (Cannibal Ferox) (1980)', 'Battle of the Sexes, The (1959)', 'Criminal Lovers (Les Amants Criminels) (1999)', 'Wedding Bell Blues (1996)', 'Buck and the Preacher (1972)', 'Two Bits (1995)', 'Telling You (1998)', 'Institute Benjamenta, or This Dream People Call Human Life (1995)', 'Map of the World, A (1999)', 'Autumn in New York (2000)']\n"
     ]
    }
   ],
   "source": [
    "Title1 = 'Autumn in New York (2000)' # First movie\n",
    "Rating1 = 4 # Rating for first movie\n",
    "\n",
    "Title2 = 'Defying Gravity (1997)' # Second movie\n",
    "Rating2 = 5 # Second rating\n",
    "\n",
    "Title3 = 'Vie est belle, La (Life is Rosey) (1987)' # Third movie\n",
    "Rating3 = 2 # Third rating\n",
    "\n",
    "Title4 = 'Ruthless People (1986)' # Fourth movie\n",
    "Rating4 = 2 # Fourth rating\n",
    "\n",
    "Title5 = 'True Lies (1994)' # Fifth movie\n",
    "Rating5 = 5 # Fifth rating\n",
    "\n",
    "feature = {'Title1':Title1, 'Title2':Title2, 'Title3':Title3, 'Title4':Title4, 'Title5':Title5,\n",
    "            'Rating1':Rating1, 'Rating2':Rating2, 'Rating3':Rating3, 'Rating4':Rating4, 'Rating5':Rating5} # Make a dictionary since this is the way the feature will appare in the app\n",
    "\n",
    "\n",
    "feature['Title1'] = float(film['FilmID'][film['Tittel'] == feature['Title1']]) # Find the filmid\n",
    "feature['Title2'] = float(film['FilmID'][film['Tittel'] == feature['Title2']]) # Find the filmid\n",
    "feature['Title3'] = float(film['FilmID'][film['Tittel'] == feature['Title3']]) # Find the filmid\n",
    "feature['Title4'] = float(film['FilmID'][film['Tittel'] == feature['Title4']]) # Find the filmid\n",
    "feature['Title5'] = float(film['FilmID'][film['Tittel'] == feature['Title5']]) # Find the filmid\n",
    "    \n",
    "filmids = [feature['Title1'], feature['Title2'], feature['Title3'], feature['Title4'], feature['Title5']]\n",
    "    \n",
    "df = pd.DataFrame(data.loc[data['FilmID'] == feature['Title1']].iloc[0]).transpose()\n",
    "df = df.append(pd.DataFrame(data.loc[data['FilmID'] == feature['Title2']].iloc[0]).transpose(), ignore_index=True)\n",
    "df = df.append(pd.DataFrame(data.loc[data['FilmID'] == feature['Title3']].iloc[0]).transpose(), ignore_index=True)\n",
    "df = df.append(pd.DataFrame(data.loc[data['FilmID'] == feature['Title4']].iloc[0]).transpose(), ignore_index=True)\n",
    "df = df.append(pd.DataFrame(data.loc[data['FilmID'] == feature['Title5']].iloc[0]).transpose(), ignore_index=True)\n",
    "    \n",
    "df['Rangering'] = [feature['Rating1'], feature['Rating2'], feature['Rating3'], feature['Rating4'], feature['Rating5']]\n",
    "df['BrukerID'] = [7000, 7000, 7000, 7000, 7000]\n",
    "    \n",
    "data = data.append(df, ignore_index=True)\n",
    "\n",
    "    \n",
    "# Make the correlation matrix\n",
    "table = pd.pivot_table(data, values='Rangering', columns='FilmID', index='BrukerID')\n",
    "bruker_mean = table.mean(axis=1)\n",
    "table = table.fillna(0.1)\n",
    "table2 = table.copy()\n",
    "table = table.transpose()\n",
    "    \n",
    "    \n",
    "for i in table.columns:\n",
    "    table[i] = table[i].replace([0.1], bruker_mean[i])\n",
    "        \n",
    "table = table.transpose()\n",
    "    \n",
    "idx = list(table.index)\n",
    "correlation_matrix = pd.DataFrame(np.corrcoef(table))\n",
    "correlation_matrix.index = idx\n",
    "correlation_matrix.columns = idx\n",
    "    \n",
    "# predict\n",
    "correlation_vector = correlation_matrix.loc[7000, :] # Extract the row in the correlation matrix which represents the user\n",
    "predictions = []\n",
    "filmid = data['FilmID'].unique().tolist()\n",
    "for i in range(len(film['FilmID'])):\n",
    "    if film['FilmID'].iloc[i] in filmids:\n",
    "        continue\n",
    "    else:\n",
    "        film_vector = table2.loc[:,filmid[i]] # Extract the column in table corresponding to the filmid\n",
    "        has_rated = film_vector.index[film_vector != 0.1].tolist() # Find every user that has rated the given filmid\n",
    "        has_rated_corr = correlation_vector[has_rated] # Find a vector with the correlations with evry person that has rated the filmid\n",
    "\n",
    "        k = 3\n",
    "        k_largest = has_rated_corr.nlargest(k) # Find the k highest correlations\n",
    "        pred = 0\n",
    "    # Calculate the predictions\n",
    "        for i in range(len(k_largest)):\n",
    "            pred += (table2.loc[k_largest.index[i], i]-bruker_mean[k_largest.index[i]])\n",
    "        predictions.append(bruker_mean.loc[7000] + (1/k)*pred)\n",
    "        filmid.append(i)\n",
    "        #film['FilmID'].iloc[i]\n",
    "\n",
    "index10 = np.argsort(predictions)[-10:]\n",
    "filmid10 = []\n",
    "for i in index10:\n",
    "    filmid10.append(filmid[i])\n",
    "\n",
    "recommended = []\n",
    "for i in filmid10:\n",
    "    recommended.append(film.loc[film['FilmID']==i]['Tittel'].iloc[0])\n",
    "    \n",
    "print(recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
